{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "We will write down some important definitions such that we can easier write down code in the future. You can find the original lecture notes [here](https://economics.mit.edu/sites/default/files/inline-files/Political%20Economy%20Lecture%20Notes.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Definitions\n",
    "\n",
    "- We numerate players as $i\\in N$, where $N$ is the number of players.\n",
    "- The player has a number of possibilities to choose from, which we denote as $A_i(k)$, where $k$ is the state vector.\n",
    "- An element of the state strategy set is denoted as $a_{it}$ with the relationship $a_t = (a_{1t}, \\dots, a_{nt})$ and $a_t \\in A_(k_t) \\equiv \\prod_i^N A_i(k_t)$.\n",
    "- We note $a_{-it} = (a_{1,t}, a_{i-1,t}, a_{i+1,t}, \\dots, a_{N,t})$ as action vector with $i$'s action\n",
    "- We further define the *instantaneous utility function* u_i(a_t, k_t) which maps the state-action pair to the real numbers.\n",
    "\n",
    "We can then say that the players attempts to maximize the expected utility function at time $t$, which is defined as:\n",
    "$$\n",
    "U_{it} = E_t\\left(\\sum_{s=0}^\\infty \\beta^s u_i(a_{t+s}, k_{t+s})\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we decide that state vector $k_t$ is a Markov process, which means that the future state is only dependent on the current state and the current action. We can then not it as $q(k_{t+1} | a_t, k_t)$. $q$ is the transition probability function. with $\\int dk_{t+1} q(k_{t+1} | a_t, k_t) = 1$.\n",
    "\n",
    "Next we define the public history at time $t$ as $h^t = (a_0, k_0, \\dots, a_t, k_t)$. The set of all possible public histories is denoted as $\\mathcal{H}^t$.\n",
    "\n",
    "The strategy of a player is a function that maps the public history to the action set. We denote the strategy of player $i$ as \n",
    "$$\n",
    "\\sigma_{it}: \\mathcal{H}^{t-1}  \\times K \\rightarrow A_i\n",
    "$$\n",
    "\n",
    "The mixed strategy of player $i$ is a probability distribution over the action set. We denote the mixed strategy of player $i$ as\n",
    "$$\n",
    "\\sigma_{it}: \\mathcal{H}^{t-1}  \\times K \\rightarrow \\Delta(A_i)\n",
    "$$\n",
    "\n",
    "\n",
    "We call the set of all feasible strategies at time $S_i[t]$. The best response correspondence is the set of all actions that maximize the expected utility function. We denote the *best response correspondence* of player $i$ as\n",
    "\n",
    "$ BR_i(\\sigma_{-i}) = \\left(\\sigma_i \\in S_i[t] \\text{ maximising the utility function}\\right)$\n",
    "\n",
    "The subgame perfect equilibrium is a strategy profile $\\sigma^*$  such that $\\sigma^*$ is part of the best response for all histories to time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes people focus on Markov Decision Problems to find a Markov Perfect Equilibrium. We then a pure Markovian strategy as \n",
    "$$\n",
    "\\hat{\\sigma}_i:K \\rightarrow A_i\n",
    "$$\n",
    "\n",
    "The Markov Perfect Equilibrium $\\hat{\\sigma}^*$ is equivalently defined as the subgame perfect equilibrium equilibrium, but only Markovian strategies are allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated games with perfect observability\n",
    "\n",
    "We can define a repeated game as a game that is played over and over again. The utility function is then\n",
    "\n",
    "$$\n",
    "U_i[t] = E_t\\left(\\sum_{s=0}^\\infty \\beta^s u_i(a_{t+s}\\right)\n",
    "$$\n",
    "\n",
    "so it does not depend on some state vector, but only on the action vector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acemoglu-lecture-WcaluVDL-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
